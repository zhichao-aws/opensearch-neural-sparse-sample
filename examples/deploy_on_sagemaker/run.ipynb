{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b32dbef8",
   "metadata": {},
   "source": [
    "/*\n",
    " * Copyright opensearch-neural-sparse-sample Contributors\n",
    " * SPDX-License-Identifier: Apache-2.0\n",
    " */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff4e2d",
   "metadata": {},
   "source": [
    "> **_NOTE:_**  **This script is supposed to be executed at SageMaker Notebook!**\n",
    "\n",
    "## prerequesites\n",
    "- We have setup an **SageMaker Notebook**, the **S3 bucket** to store the bindle, and config their permission\n",
    "\n",
    "## Step 1\n",
    "Use git to clone this branch to your SageMaker Notebook instance, and open this run.ipynb at your SageMaker Notebook\n",
    "\n",
    "## Step 2\n",
    "Wrap the handler folder to a tarball. And upload it to your S3 bucket.\n",
    "\n",
    "In handler/neural_sparse_handler.py, we define the model loading, pre-process, inference and post-process. We use mixed-precision to accelerate the inference.\n",
    "\n",
    "In handler/neural_sparse_config.yaml, we define some configs for the torch serve (include dynamic micro-batching)\n",
    "\n",
    "> **_NOTE:_**  By default we deploy the opensearch-project/opensearch-neural-sparse-encoding-v1 model. To deploy other models, please change the model_id parameter at handler/neural_sparse_handler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22168fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "!tar -czvf neural-sparse-handler.tar.gz -C handler/ .\n",
    "!aws s3 cp neural-sparse-handler.tar.gz s3://{YOUR_BUCKET_PREFIX}/neural-sparse-handler.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161796c1",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Use SageMaker python SDK to deploy the tarball on a real-time inference endpoint\n",
    "\n",
    "Here we use ml.g5.xlarge. It's a GPU instance with good price-performance.\n",
    "\n",
    "Please modify the region base according to your settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d16be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "region = sess.region_name\n",
    "account = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "smsess = sagemaker.Session(boto_session=sess)\n",
    "envs = {\n",
    "    \"TS_ASYNC_LOGGING\":\"true\",\n",
    "    \"TS_JOB_QUEUE_SIZE\":\"1000\"\n",
    "}\n",
    "\n",
    "baseimage = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region='us-east-1',\n",
    "    py_version=\"py312\",\n",
    "    image_scope=\"inference\",\n",
    "    version=\"2.6\",\n",
    "    instance_type=\"ml.g6.xlarge\",\n",
    ")\n",
    "\n",
    "model = Model(model_data = \"s3://{YOUR_BUCKET_PREFIX}/neural-sparse-handler.tar.gz\",\n",
    "    image_uri = baseimage,\n",
    "    role = role,\n",
    "    predictor_cls = Predictor,\n",
    "    name = \"ns-handler\",\n",
    "    sagemaker_session = smsess,\n",
    "    env=envs\n",
    ")\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "endpoint_name = \"ns-handler\"\n",
    "predictor = model.deploy(instance_type='ml.g5.xlarge',\n",
    "                         initial_instance_count=1,\n",
    "                         endpoint_name = endpoint_name,\n",
    "                         serializer=JSONSerializer(),\n",
    "                         deserializer=JSONDeserializer(),\n",
    "                        ModelDataDownloadTimeoutInSeconds=3600,\n",
    "                        ContainerStartupHealthCheckTimeoutInSeconds=3600,\n",
    "                        VolumeSizeInGB=64)\n",
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863ed26",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "After we create the endpoint, use some sample request to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "import json\n",
    "\n",
    "body = [\"hello world\"]\n",
    "amz = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = amz.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    Body=json.dumps(body),\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "res = response['Body'].read()\n",
    "results = json.loads(res.decode(\"utf8\"))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33035889",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "> **_NOTE:_**  **This step is supposed to be executed at an instance have access to OpenSearch cluster!**\n",
    "\n",
    "Register this SageMaker endpoint at your OpenSearch cluster\n",
    "\n",
    "Please check the OpenSearch doc for more information. Here we provide one demo request body using access_key and secret_key. Please choose the authentication according to your use case.\n",
    "\n",
    "### create connector\n",
    "\n",
    "(Please fill the predictor.endpoint_name at the url)\n",
    "```json\n",
    "{\n",
    "  \"name\": \"test\",\n",
    "  \"description\": \"Test connector for Sagemaker model\",\n",
    "  \"version\": 1,\n",
    "  \"protocol\": \"aws_sigv4\",\n",
    "  \"credential\": {\n",
    "    \"access_key\": \"your access key\",\n",
    "    \"secret_key\": \"your secret key\"\n",
    "  },\n",
    "  \"parameters\": {\n",
    "    \"region\": \"{region}\",\n",
    "    \"service_name\": \"sagemaker\",\n",
    "    \"input_docs_processed_step_size\": 2,\n",
    "  },\n",
    "  \"actions\": [\n",
    "    {\n",
    "      \"action_type\": \"predict\",\n",
    "      \"method\": \"POST\",\n",
    "      \"headers\": {\n",
    "        \"content-type\": \"application/json\"\n",
    "      },\n",
    "      \"url\": \"https://runtime.sagemaker.{region}.amazonaws.com/endpoints/{predictor.endpoint_name}/invocations\",\n",
    "      \"request_body\": \"${parameters.input}\"\n",
    "    }\n",
    "  ],\n",
    "  \"client_config\":{\n",
    "      \"max_retry_times\": -1,\n",
    "      \"max_connection\": 60,\n",
    "      \"retry_backoff_millis\": 10\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### register model\n",
    "```json\n",
    "{\n",
    "  \"name\": \"test\",\n",
    "  \"function_name\": \"remote\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"connector_id\": \"{connector id}\",\n",
    "  \"description\": \"Test connector for Sagemaker model\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fda443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
